(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{87:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return r})),a.d(t,"metadata",(function(){return c})),a.d(t,"rightToc",(function(){return l})),a.d(t,"default",(function(){return d}));var n=a(3),i=a(7),o=(a(0),a(91)),r={title:"Point Cloud With Images (v0)"},c={unversionedId:"input-api/inputs/point_cloud_with_images",id:"input-api/inputs/point_cloud_with_images",isDocsHomePage:!1,title:"Point Cloud With Images (v0)",description:"Supported point cloud formats are .csv, .pcd or .las",source:"@site/docs/input-api/inputs/point_cloud_with_images.md",slug:"/input-api/inputs/point_cloud_with_images",permalink:"/annotell-python/docs/input-api/inputs/point_cloud_with_images",editUrl:"https://github.com/annotell/annotell-python/edit/gh-pages/docs-src/docs/input-api/inputs/point_cloud_with_images.md",version:"current",sidebar:"docs",previous:{title:"Point Cloud (v0)",permalink:"/annotell-python/docs/input-api/inputs/point_cloud"},next:{title:"Cameras \ud83d\udea7",permalink:"/annotell-python/docs/input-api/inputs/cameras"}},l=[{value:"Single Image and Single Point Cloud Example",id:"single-image-and-single-point-cloud-example",children:[{value:"Adding metadata to the input",id:"adding-metadata-to-the-input",children:[]},{value:"Creating the input",id:"creating-the-input",children:[]},{value:"Full example code",id:"full-example-code",children:[]}]}],p={rightToc:l};function d(e){var t=e.components,a=Object(i.a)(e,["components"]);return Object(o.b)("wrapper",Object(n.a)({},p,a,{components:t,mdxType:"MDXLayout"}),Object(o.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})))),"Supported point cloud formats")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"Supported point cloud formats are ",Object(o.b)("inlineCode",{parentName:"p"},".csv"),", ",Object(o.b)("inlineCode",{parentName:"p"},".pcd")," or ",Object(o.b)("inlineCode",{parentName:"p"},".las")))),Object(o.b)("p",null,"A ",Object(o.b)("inlineCode",{parentName:"p"},"PointCloudsWithImages")," input is very similar to the ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"/annotell-python/docs/input-api/inputs/images"}),Object(o.b)("inlineCode",{parentName:"a"},"Images"))," input, except that we in addition to camera images also supply lidar point clouds. In order to relate the lidar representation to the cameras a calibration is needed as well. The calibration enables projection of cuboids in the point cloud down onto the camera images, which can help guide annotators in producing annotations. For more information on how to define and create a calibration, please refer to the ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"/annotell-python/docs/input-api/calibration"}),"Calibration")," section."),Object(o.b)("h2",{id:"single-image-and-single-point-cloud-example"},"Single Image and Single Point Cloud Example"),Object(o.b)("p",null,"The first step is to produce an ",Object(o.b)("inlineCode",{parentName:"p"},"Image")," object for the camera image, as well as a ",Object(o.b)("inlineCode",{parentName:"p"},"PointCloud")," object for the lidar point cloud. It's important to specify the right source name for our image and point cloud, since these source names will need to be present in the calibration as well. In this case the source name of the image is ",Object(o.b)("inlineCode",{parentName:"p"},'"RFC01"'),", whereas for the point cloud we will go with the default source name of ",Object(o.b)("inlineCode",{parentName:"p"},'"lidar"'),"."),Object(o.b)("div",{className:"admonition admonition-info alert alert--info"},Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})))),"no multi-lidar support currently")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"Currently there is only support for supplying a single point cloud"))),Object(o.b)("pre",null,Object(o.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),'import annotell.input_api.model as IAM\n\nimage1 = IAM.Image(filename="filename_image1.jpg", source="RFC01")\npc = IAM.PointCloud(filename="filename_pc.pcd")\npoint_clouds_with_images = IAM.PointCloudsWithImages(images=[image1],\n                                                     point_clouds=[pc])\nfolder = Path("/home/user_name/example_path/")  # Folder to where the data is\n')),Object(o.b)("h3",{id:"adding-metadata-to-the-input"},"Adding metadata to the input"),Object(o.b)("p",null,"Next, we need to add metadata to the input. Similarly to ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"/annotell-python/docs/input-api/inputs/images"}),Object(o.b)("inlineCode",{parentName:"a"},"Images"))," inputs, we can specify the ",Object(o.b)("inlineCode",{parentName:"p"},"external_id")," and ",Object(o.b)("inlineCode",{parentName:"p"},"source_specification"),". However we are also ",Object(o.b)("em",{parentName:"p"},"required")," to specify a ",Object(o.b)("inlineCode",{parentName:"p"},"calibration_id")," in order to create the input."),Object(o.b)("pre",null,Object(o.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),'scene_external_id = "Scene X collection 2020-06-16"\ncalibration_id = 100\nmetadata = IAM.CalibratedSceneMetaData(external_id=scene_external_id,\n                                       calibration_id=calibration_id)\n')),Object(o.b)("table",null,Object(o.b)("thead",{parentName:"table"},Object(o.b)("tr",{parentName:"thead"},Object(o.b)("th",Object(n.a)({parentName:"tr"},{align:null}),"Parameter"),Object(o.b)("th",Object(n.a)({parentName:"tr"},{align:null}),"Description"))),Object(o.b)("tbody",{parentName:"table"},Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",Object(n.a)({parentName:"tr"},{align:null}),"external_id"),Object(o.b)("td",Object(n.a)({parentName:"tr"},{align:null}),"Id which can be used to track progress of annotations with.")),Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",Object(n.a)({parentName:"tr"},{align:null}),"source_specification"),Object(o.b)("td",Object(n.a)({parentName:"tr"},{align:null}),"Additional information about sources, includes ",Object(o.b)("inlineCode",{parentName:"td"},"source_to_pretty_name")," and ",Object(o.b)("inlineCode",{parentName:"td"},"source_order"),". ",Object(o.b)("inlineCode",{parentName:"td"},"source_order")," is a list of strings that defines the order in which the sources will be shown in the UI, while ",Object(o.b)("inlineCode",{parentName:"td"},"source_to_pretty_name")," can be used to provide a mapping of a source name to a more intuitive name that will be displayed in the UI.")),Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",Object(n.a)({parentName:"tr"},{align:null}),"calibration_id"),Object(o.b)("td",Object(n.a)({parentName:"tr"},{align:null}),"Which calibration to use for the input.")))),Object(o.b)("p",null,"See the ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"/annotell-python/docs/input-api/calibration"}),"Calibration")," section for more information on how to retrieve a calibration id."),Object(o.b)("h3",{id:"creating-the-input"},"Creating the input"),Object(o.b)("p",null,"The final step is to create the input."),Object(o.b)("pre",null,Object(o.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),'import annotell.input_api.input_api_client as IAC\nclient = IAC.InputApiClient()\n\nclient.create_inputs_point_cloud_with_images(folder=folder,\n                                             point_clouds_with_images=point_clouds_with_images,\n                                             metadata=metadata,\n                                             project="my_project")\n')),Object(o.b)("h3",{id:"full-example-code"},"Full example code"),Object(o.b)("blockquote",null,Object(o.b)("p",{parentName:"blockquote"},"Full example for creating an input consisting of a point cloud and one image. Also includes creation of a new calibration. ")),Object(o.b)("div",{className:"admonition admonition-tip alert alert--success"},Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})))),"reuse calibration")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"Note that you can, and should, reuse the same calibration for multiple inputs if possible."))),Object(o.b)("pre",null,Object(o.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),'import annotell.input_api.input_api_model as IAM\nimport annotell.input_api.model.calibration as Calibration\nimport annotell.input_api.input_api_client as IAC\nfrom pathlib import Path\nclient = IAC.InputApiClient()\n# Create representation of images and point clouds + source specification images\nimage1 = IAM.Image(filename="filename_image1.jpg", source="RFC01")\npc = IAM.PointCloud(filename="filename_pc.pcd")\npoint_clouds_with_images = IAM.PointCloudsWithImages(images=[image1],\n                                                     point_clouds=[pc])\nfolder = Path("/home/user_name/example_path/")  # Folder to where the data is\n# Create lidar calibration\nlidar_position = Calibration.Position(x=0.0, y=0.0, z=0.0)\nlidar_rotation = Calibration.RotationQuaternion(w=1.0, x=0.0, y=0.0, z=0.0)\nlidar_calibration = Calibration.LidarCalibrationExplicit(position=lidar_position,\n                                                         rotation_quaternion=lidar_rotation)\n# Create a camera calibration\nrfc_01_camera_type = Calibration.CameraType.PINHOLE\nrfc_01_position = Calibration.Position(x=0.0, y=0.0, z=0.0)  # similar to Lidar\nrfc_01_rotation = Calibration.RotationQuaternion(w=1.0, x=0.0, y=0.0, z=0.0)  # similar to Lidar\nrfc_01_camera_matrix = Calibration.CameraMatrix(fx=3450, fy=3250, cx=622, cy=400)\nrfc_01_distortion_coefficients = Calibration.DistortionCoefficients(k1=0.0, k2=0.0, p1=0.0, p2=0.0, k3=0.0)\nrfc_01_properties = Calibration.CameraProperty(camera_type=rfc_01_camera_type)\ncamera_calibration_rfc_01 = Calibration.CameraCalibrationExplicit(\n    position=rfc_01_position,\n    rotation_quaternion=rfc_01_rotation,\n    camera_matrix=rfc_01_camera_matrix,\n    distortion_coefficients=rfc_01_distortion_coefficients,\n    camera_properties=rfc_01_properties,\n    image_height=920,\n    image_width=1244\n)\n\n# Create calibration for the scene\ncalibration_dict = dict(RFC01=camera_calibration_rfc_01,\n                        lidar=lidar_calibration)\ncalibration = IAM.Calibration(calibration_dict=calibration_dict)\ncalibration_external_id = "Collection 2020-06-16"\ncalibration_spec = IAM.CalibrationSpec(external_id=calibration_external_id,\n                                       calibration=calibration)\n# Create the calibration using the Input API client\ncreated_calibration = client.create_calibration_data(calibration_spec=calibration_spec)\n\n# Create metadata\nscene_external_id = "Scene X collection 2020-06-16"\nmetadata = IAM.CalibratedSceneMetaData(external_id=scene_external_id,\n                                       calibration_id=created_calibration.id)\n\n# Add input\nclient.create_inputs_point_cloud_with_images(folder=folder,\n                                             point_clouds_with_images=point_clouds_with_images,\n                                             metadata=metadata,\n                                             project="my_project")\n')))}d.isMDXComponent=!0},91:function(e,t,a){"use strict";a.d(t,"a",(function(){return s})),a.d(t,"b",(function(){return u}));var n=a(0),i=a.n(n);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function c(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var p=i.a.createContext({}),d=function(e){var t=i.a.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):c(c({},t),e)),a},s=function(e){var t=d(e.components);return i.a.createElement(p.Provider,{value:t},e.children)},b={inlineCode:"code",wrapper:function(e){var t=e.children;return i.a.createElement(i.a.Fragment,{},t)}},m=i.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,r=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),s=d(a),m=n,u=s["".concat(r,".").concat(m)]||s[m]||b[m]||o;return a?i.a.createElement(u,c(c({ref:t},p),{},{components:a})):i.a.createElement(u,c({ref:t},p))}));function u(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,r=new Array(o);r[0]=m;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c.mdxType="string"==typeof e?e:n,r[1]=c;for(var p=2;p<o;p++)r[p]=a[p];return i.a.createElement.apply(null,r)}return i.a.createElement.apply(null,a)}m.displayName="MDXCreateElement"}}]);