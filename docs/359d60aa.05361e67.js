(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{107:function(e,t,n){"use strict";n.r(t),n.d(t,"MDXContext",(function(){return p})),n.d(t,"MDXProvider",(function(){return u})),n.d(t,"mdx",(function(){return b})),n.d(t,"useMDXComponents",(function(){return d})),n.d(t,"withMDXComponents",(function(){return l}));var a=n(0),r=n.n(a);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(){return(o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e}).apply(this,arguments)}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function m(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=r.a.createContext({}),l=function(e){return function(t){var n=d(t.components);return r.a.createElement(e,o({},t,{components:n}))}},d=function(e){var t=r.a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):m(m({},t),e)),n},u=function(e){var t=d(e.components);return r.a.createElement(p.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},f=r.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,o=e.parentName,s=c(e,["components","mdxType","originalType","parentName"]),p=d(n),l=a,u=p["".concat(o,".").concat(l)]||p[l]||h[l]||i;return n?r.a.createElement(u,m(m({ref:t},s),{},{components:n})):r.a.createElement(u,m({ref:t},s))}));function b(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=f;var s={};for(var m in t)hasOwnProperty.call(t,m)&&(s[m]=t[m]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var c=2;c<i;c++)o[c]=n[c];return r.a.createElement.apply(null,o)}return r.a.createElement.apply(null,n)}f.displayName="MDXCreateElement"},40:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return i})),n.d(t,"metadata",(function(){return o})),n.d(t,"rightToc",(function(){return s})),n.d(t,"default",(function(){return c}));var a=n(3),r=(n(0),n(107));const i={title:"CamerasSeq"},o={unversionedId:"input-api/inputs/cameras_seq",id:"input-api/inputs/cameras_seq",isDocsHomePage:!1,title:"CamerasSeq",description:"A CamerasSeq input consists of a sequence of camera images. Unlike single-frame input types you also have to specify the sequential relationship between the frames, where each frame consists on 1-8 camera images.",source:"@site/docs/input-api/inputs/cameras_seq.md",slug:"/input-api/inputs/cameras_seq",permalink:"/annotell-python/docs/input-api/inputs/cameras_seq",editUrl:"https://github.com/annotell/annotell-python/edit/gh-pages/docs-src/docs/input-api/inputs/cameras_seq.md",version:"current",sidebar:"docs",previous:{title:"LidarsAndCameras",permalink:"/annotell-python/docs/input-api/inputs/lidars_and_cameras"},next:{title:"LidarsSeq \ud83d\udea7",permalink:"/annotell-python/docs/input-api/inputs/lidars_seq"}},s=[{value:"Creating a list of frames",id:"creating-a-list-of-frames",children:[]},{value:"Creating the input",id:"creating-the-input",children:[]}],m={rightToc:s};function c({components:e,...t}){return Object(r.mdx)("wrapper",Object(a.default)({},m,t,{components:e,mdxType:"MDXLayout"}),Object(r.mdx)("p",null,"A ",Object(r.mdx)("inlineCode",{parentName:"p"},"CamerasSeq")," input consists of a sequence of camera images. Unlike single-frame input types you also have to specify the sequential relationship between the ",Object(r.mdx)("em",{parentName:"p"},"frames"),", where each frame consists on 1-8 camera images."),Object(r.mdx)("h2",{id:"creating-a-list-of-frames"},"Creating a list of frames"),Object(r.mdx)("p",null,"The sequential relationship is expressed via a list of ",Object(r.mdx)("inlineCode",{parentName:"p"},"Frame")," objects. This representation expresses the ordering of the frames, but it does not include the ",Object(r.mdx)("em",{parentName:"p"},"relative temporal")," relationship between the frames in the list."),Object(r.mdx)("pre",null,Object(r.mdx)("code",{parentName:"pre",className:"language-python"},"frame_1 = IAM.Frame(...)\nframe_2 = IAM.Frame(...)\nframes = [frame_1, frame_2]\n")),Object(r.mdx)("p",null,"In other words, this representation captures that ",Object(r.mdx)("inlineCode",{parentName:"p"},"frame_1")," comes before ",Object(r.mdx)("inlineCode",{parentName:"p"},"frame_2"),", but does not express how much time has passed between the two frames. In order to express how much time has passed between the frames we need to specify the field ",Object(r.mdx)("inlineCode",{parentName:"p"},"relative_timestamp")," for each frame object. If we for example know that we have collected and aggregated our sensor data at 2Hz, then we would express that as"),Object(r.mdx)("pre",null,Object(r.mdx)("code",{parentName:"pre",className:"language-python"},"frame_1 = IAM.Frame(..., relative_timestamp=0)\nframe_2 = IAM.Frame(..., relative_timestamp=500)\nframes = [frame_1, frame_2]\n")),Object(r.mdx)("div",{className:"admonition admonition-tip alert alert--success"},Object(r.mdx)("div",{parentName:"div",className:"admonition-heading"},Object(r.mdx)("h5",{parentName:"div"},Object(r.mdx)("span",{parentName:"h5",className:"admonition-icon"},Object(r.mdx)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},Object(r.mdx)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"Why is relative time important?")),Object(r.mdx)("div",{parentName:"div",className:"admonition-content"},Object(r.mdx)("p",{parentName:"div"},"Specifying the time relationship between frames is important in order to enable different types of advanced annotator assistance tools in the Annotell platform. These tools enable a ",Object(r.mdx)("strong",{parentName:"p"},"significant")," reduction in annotation time, while keeping quality high."))),Object(r.mdx)("h2",{id:"creating-the-input"},"Creating the input"),Object(r.mdx)("p",null,"In addition to supplying the sequential and temporal information for our ",Object(r.mdx)("inlineCode",{parentName:"p"},"Frame")," objects we also need to specify the camera images that constitute each frame. This is done by passing a list of ",Object(r.mdx)("inlineCode",{parentName:"p"},"ImageFrame")," objects, where each of these objects contains the path to the underlying file as well as the sensor name. Finally, we also need to specify the ",Object(r.mdx)("inlineCode",{parentName:"p"},"frame_id")," of each frame."),Object(r.mdx)("p",null,"In order to create the input we need to use our list of ",Object(r.mdx)("inlineCode",{parentName:"p"},"Frame")," objects and specify the parameters ",Object(r.mdx)("inlineCode",{parentName:"p"},"external_id")," and ",Object(r.mdx)("inlineCode",{parentName:"p"},"sensor_specification"),"."),Object(r.mdx)("table",null,Object(r.mdx)("thead",{parentName:"table"},Object(r.mdx)("tr",{parentName:"thead"},Object(r.mdx)("th",{parentName:"tr",align:null},"Parameter"),Object(r.mdx)("th",{parentName:"tr",align:null},"Description"))),Object(r.mdx)("tbody",{parentName:"table"},Object(r.mdx)("tr",{parentName:"tbody"},Object(r.mdx)("td",{parentName:"tr",align:null},"external_id"),Object(r.mdx)("td",{parentName:"tr",align:null},"Id which can be used to track progress of annotations with.")),Object(r.mdx)("tr",{parentName:"tbody"},Object(r.mdx)("td",{parentName:"tr",align:null},"sensor_specification"),Object(r.mdx)("td",{parentName:"tr",align:null},"Additional information about sensors, includes ",Object(r.mdx)("inlineCode",{parentName:"td"},"sensor_to_pretty_name")," and ",Object(r.mdx)("inlineCode",{parentName:"td"},"sensor_order"),". Defines which sensor that should be shown first, the sensor_order, or a mapping of sensor names to a prettier name version displayed in the Annotell Annotation Tool.")))),Object(r.mdx)("pre",null,Object(r.mdx)("code",{parentName:"pre",className:"language-python",metastring:"reference",reference:!0},"https://github.com/annotell/annotell-python/blob/master/annotell-input-api/examples/cameras_seq.py\n")),Object(r.mdx)("div",{className:"admonition admonition-tip alert alert--success"},Object(r.mdx)("div",{parentName:"div",className:"admonition-heading"},Object(r.mdx)("h5",{parentName:"div"},Object(r.mdx)("span",{parentName:"h5",className:"admonition-icon"},Object(r.mdx)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},Object(r.mdx)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"Use dryrun to validate input")),Object(r.mdx)("div",{parentName:"div",className:"admonition-content"},Object(r.mdx)("p",{parentName:"div"},"Setting ",Object(r.mdx)("inlineCode",{parentName:"p"},"dryrun")," parameter to true in the method call, will validate the input using the Input API but not create any inputs."))))}c.isMDXComponent=!0}}]);